{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = { \n",
    "    \"Freezing\": 0, \n",
    "    \"Warm\": 1, \n",
    "    \"Cold\": 2, \n",
    "    \"Boiling Hot\": 3, \n",
    "    \"Hot\": 4, \n",
    "    \"Lava Hot\": 5   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ord_2\n",
       "Freezing       99816\n",
       "Lava Hot       63908\n",
       "Boiling Hot    60627\n",
       "Cold           33768\n",
       "Hot            22227\n",
       "Warm           19654\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    " \n",
    "df = pd.read_csv(\"train.csv\") \n",
    "df.ord_2.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, \"ord_2\"] = df.ord_2.map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ord_2\n",
       "0    99816\n",
       "5    63908\n",
       "3    60627\n",
       "2    33768\n",
       "4    22227\n",
       "1    19654\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ord_2.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn import preprocessing \n",
    " \n",
    "# read the data \n",
    "df = pd.read_csv(\"train.csv\") \n",
    " \n",
    "# fill NaN values in ord_2 column \n",
    "df.loc[:, \"ord_2\"] = df.ord_2.fillna(\"NONE\") \n",
    " \n",
    "# initialize LabelEncoder \n",
    "lbl_enc = preprocessing.LabelEncoder() \n",
    " \n",
    "# fit label encoder and transform values on ord_2 column \n",
    "# P.S: do not use this directly. fit first, then transform \n",
    "df.loc[:, \"ord_2\"] = lbl_enc.fit_transform(df.ord_2.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ord_2\n",
       "0    60627\n",
       "1    33768\n",
       "2    99816\n",
       "3    22227\n",
       "4    63908\n",
       "5    19654\n",
       "Name: id, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " df.groupby([\"ord_2\"])[\"id\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_folds.py \n",
    "# import pandas and model_selection module of scikit-learn \n",
    "import pandas as pd \n",
    "from sklearn import model_selection \n",
    " \n",
    "if __name__ == \"__main__\": \n",
    " \n",
    "    # Read training data \n",
    "    df = pd.read_csv(\"train.csv\") \n",
    " \n",
    "    # we create a new column called kfold and fill it with -1 \n",
    "    df[\"kfold\"] = -1 \n",
    "     \n",
    "    # the next step is to randomize the rows of the data \n",
    "    df = df.sample(frac=1).reset_index(drop=True) \n",
    "     \n",
    "    # fetch labels \n",
    "    y = df.target.values \n",
    "     \n",
    "    # initiate the kfold class from model_selection module \n",
    "    kf = model_selection.StratifiedKFold(n_splits=5) \n",
    "     \n",
    "    # fill the new kfold column \n",
    "    for f, (t_, v_) in enumerate(kf.split(X=df, y=y)): \n",
    "        df.loc[v_, 'kfold'] = f \n",
    "     \n",
    "    # save the new csv with kfold column \n",
    "    df.to_csv(\"cat_train_folds.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "kfold\n",
       "0    60000\n",
       "1    60000\n",
       "2    60000\n",
       "3    60000\n",
       "4    60000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"cat_train_folds.csv\")\n",
    "\n",
    "df.kfold.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    41648\n",
       "1    18352\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.kfold==0].target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  logistic regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    " \n",
    "from sklearn import linear_model \n",
    "from sklearn import metrics \n",
    "from sklearn import preprocessing \n",
    " \n",
    "def run(fold): \n",
    "    # load the full training data with folds \n",
    "    df = pd.read_csv(\"cat_train_folds.csv\")\n",
    " \n",
    "    # all columns are features except id, target and kfold columns \n",
    "    features = [ \n",
    "        f for f in df.columns if f not in (\"id\", \"target\", \"kfold\") \n",
    "    ] \n",
    " \n",
    "    # fill all NaN values with NONE \n",
    "    # note that I am converting all columns to \"strings\" \n",
    "    # it doesnâ€™t matter because all are categories \n",
    "    for col in features: \n",
    "        df.loc[:, col] = df[col].astype(str).fillna(\"NONE\") \n",
    "     \n",
    "    # get training data using folds \n",
    "    df_train = df[df.kfold != fold].reset_index(drop=True) \n",
    " \n",
    "    # get validation data using folds \n",
    "    df_valid = df[df.kfold == fold].reset_index(drop=True) \n",
    " \n",
    "    # initialize OneHotEncoder from scikit-learn \n",
    "    ohe = preprocessing.OneHotEncoder() \n",
    " \n",
    "    # fit ohe on training + validation features \n",
    "    full_data = pd.concat( \n",
    "        [df_train[features], df_valid[features]], \n",
    "        axis=0 \n",
    "    ) \n",
    "    ohe.fit(full_data[features]) \n",
    " \n",
    "    # transform training data \n",
    "    x_train = ohe.transform(df_train[features]) \n",
    " \n",
    "    # transform validation data \n",
    "    x_valid = ohe.transform(df_valid[features]) \n",
    " \n",
    "    # initialize Logistic Regression model \n",
    "    model = linear_model.LogisticRegression() \n",
    "    # fit model on training data (ohe) \n",
    "    model.fit(x_train, df_train.target.values) \n",
    " \n",
    "    # predict on validation data \n",
    "    # we need the probability values as we are calculating AUC \n",
    "    # we will use the probability of 1s \n",
    "    valid_preds = model.predict_proba(x_valid)[:, 1] \n",
    " \n",
    "    # get roc auc score \n",
    "    auc = metrics.roc_auc_score(df_valid.target.values, valid_preds) \n",
    " \n",
    "    # print auc \n",
    "    print(f\"Fold = {fold}, AUC = {auc}\")  \n",
    " \n",
    " \n",
    "if __name__ == \"__main__\": \n",
    "    for fold_ in range(5): \n",
    "        run(fold_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## randomforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold = 0, AUC = 0.7352373115553327\n",
      "Fold = 1, AUC = 0.7369760420886947\n",
      "Fold = 2, AUC = 0.7333835348958494\n",
      "Fold = 3, AUC = 0.7350728302544831\n",
      "Fold = 4, AUC = 0.7353623177343978\n"
     ]
    }
   ],
   "source": [
    "# lbl_rf.py \n",
    "import pandas as pd \n",
    " \n",
    "from sklearn import ensemble \n",
    "from sklearn import metrics \n",
    "from sklearn import preprocessing \n",
    " \n",
    " \n",
    "def run(fold): \n",
    " \n",
    "    # load the full training data with folds \n",
    "    df = pd.read_csv(\"cat_train_folds.csv\")\n",
    " \n",
    "    # all columns are features except id, target and kfold columns \n",
    "    features = [ \n",
    "        f for f in df.columns if f not in (\"id\", \"target\", \"kfold\") \n",
    "    ] \n",
    " \n",
    "    # fill all NaN values with NONE \n",
    "    # note that I am converting all columns to \"strings\" \n",
    "    # it doesnt matter because all are categories \n",
    "    for col in features: \n",
    "        df.loc[:, col] = df[col].astype(str).fillna(\"NONE\") \n",
    "     \n",
    "    # now its time to label encode the features \n",
    "    for col in features: \n",
    "         \n",
    "        # initialize LabelEncoder for each feature column \n",
    "        lbl = preprocessing.LabelEncoder() \n",
    "         \n",
    "        # fit label encoder on all data \n",
    "        lbl.fit(df[col]) \n",
    " \n",
    "        # transform all the data \n",
    "        df.loc[:, col] = lbl.transform(df[col]) \n",
    " \n",
    "    # get training data using folds \n",
    "    df_train = df[df.kfold != fold].reset_index(drop=True) \n",
    " \n",
    "    # get validation data using folds \n",
    "    df_valid = df[df.kfold == fold].reset_index(drop=True) \n",
    " \n",
    "    # get training data \n",
    "    x_train = df_train[features].values \n",
    " \n",
    "    # get validation data \n",
    "    x_valid = df_valid[features].values \n",
    " \n",
    "    # initialize random forest model \n",
    "    model = ensemble.RandomForestClassifier(n_jobs=-1) \n",
    " \n",
    "    # fit model on training data (ohe) \n",
    "    model.fit(x_train, df_train.target.values) \n",
    " \n",
    "    # predict on validation data \n",
    "    # we need the probability values as we are calculating AUC \n",
    "    # we will use the probability of 1s \n",
    "    valid_preds = model.predict_proba(x_valid)[:, 1] \n",
    " \n",
    "    # get roc auc score \n",
    "    auc = metrics.roc_auc_score(df_valid.target.values, valid_preds) \n",
    " \n",
    "    # print auc \n",
    "    print(f\"Fold = {fold}, AUC = {auc}\") \n",
    " \n",
    " \n",
    "if __name__ == \"__main__\": \n",
    "    for fold_ in range(5): \n",
    "        run(fold_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold = 0, AUC = 0.7612318825808679\n",
      "Fold = 1, AUC = 0.7625039973479808\n",
      "Fold = 2, AUC = 0.7594118209006878\n",
      "Fold = 3, AUC = 0.7613782461383451\n",
      "Fold = 4, AUC = 0.760830631918779\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb \n",
    " \n",
    "from sklearn import metrics \n",
    "from sklearn import preprocessing \n",
    " \n",
    " \n",
    "def run(fold): \n",
    "    # load the full training data with folds \n",
    "    df = pd.read_csv(\"cat_train_folds.csv\")\n",
    " \n",
    "    # all columns are features except id, target and kfold columns \n",
    "    features = [ \n",
    "        f for f in df.columns if f not in (\"id\", \"target\", \"kfold\") \n",
    "    ] \n",
    " \n",
    "    # fill all NaN values with NONE \n",
    "    # note that I am converting all columns to \"strings\" \n",
    "    # it doesnt matter because all are categories \n",
    "    for col in features: \n",
    "        df.loc[:, col] = df[col].astype(str).fillna(\"NONE\") \n",
    "     \n",
    "    # now itâ€™s time to label encode the features \n",
    "    for col in features: \n",
    "         \n",
    "        # initialize LabelEncoder for each feature column \n",
    "        lbl = preprocessing.LabelEncoder() \n",
    "         \n",
    "        # fit label encoder on all data \n",
    "        lbl.fit(df[col]) \n",
    " \n",
    "        # transform all the data \n",
    "        df.loc[:, col] = lbl.transform(df[col]) \n",
    " \n",
    "    # get training data using folds \n",
    "    df_train = df[df.kfold != fold].reset_index(drop=True) \n",
    " \n",
    "    # get validation data using folds \n",
    "    df_valid = df[df.kfold == fold].reset_index(drop=True) \n",
    " \n",
    "    # get training data \n",
    "    x_train = df_train[features].values \n",
    " \n",
    "    # get validation data \n",
    "    x_valid = df_valid[features].values \n",
    " \n",
    "    # initialize xgboost model \n",
    "    model = xgb.XGBClassifier( \n",
    "        n_jobs=-1,  \n",
    "        max_depth=7, \n",
    "        n_estimators=200 \n",
    "    ) \n",
    " \n",
    "    # fit model on training data (ohe) \n",
    "    model.fit(x_train, df_train.target.values) \n",
    " \n",
    "    # predict on validation data \n",
    "    # we need the probability values as we are calculating AUC \n",
    "    # we will use the probability of 1s \n",
    "    valid_preds = model.predict_proba(x_valid)[:, 1] \n",
    " \n",
    "    # get roc auc score \n",
    "    auc = metrics.roc_auc_score(df_valid.target.values, valid_preds) \n",
    " \n",
    "    # print auc \n",
    "    print(f\"Fold = {fold}, AUC = {auc}\") \n",
    " \n",
    " \n",
    "if __name__ == \"__main__\": \n",
    "    for fold_ in range(5): \n",
    "        run(fold_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  US adult census data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('adult.data',  header=None)\n",
    "df.columns=['age','workclass','fnlwgt','education' ,'education.num','marital.status ','occupation' ,\n",
    "'relationship' ,\n",
    "'race' ,\n",
    "'sex' ,\n",
    "'capital.gain',\n",
    "'capital.loss',\n",
    "'hours.per.week',\n",
    "'native.country ',\n",
    "'income']\n",
    "df.to_csv(\"adult.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                0\n",
       "workclass          0\n",
       "fnlwgt             0\n",
       "education          0\n",
       "education.num      0\n",
       "marital.status     0\n",
       "occupation         0\n",
       "relationship       0\n",
       "race               0\n",
       "sex                0\n",
       "capital.gain       0\n",
       "capital.loss       0\n",
       "hours.per.week     0\n",
       "native.country     0\n",
       "income             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('adult.csv')\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_folds.py \n",
    "# import pandas and model_selection module of scikit-learn \n",
    "import pandas as pd \n",
    "from sklearn import model_selection \n",
    " \n",
    "if __name__ == \"__main__\": \n",
    " \n",
    "    # Read training data \n",
    "    df = pd.read_csv('adult.csv')\n",
    " \n",
    "    # we create a new column called kfold and fill it with -1 \n",
    "    df[\"kfold\"] = -1 \n",
    "     \n",
    "    # the next step is to randomize the rows of the data \n",
    "    df = df.sample(frac=1).reset_index(drop=True) \n",
    "     \n",
    "    # fetch labels \n",
    "    y = df.income.values \n",
    "     \n",
    "    # initiate the kfold class from model_selection module \n",
    "    kf = model_selection.StratifiedKFold(n_splits=5) \n",
    "     \n",
    "    # fill the new kfold column \n",
    "    for f, (t_, v_) in enumerate(kf.split(X=df, y=y)): \n",
    "        df.loc[v_, 'kfold'] = f \n",
    "     \n",
    "    # save the new csv with kfold column \n",
    "    df.to_csv(\"adult_folds.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "      <th>income</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "      <td>Private</td>\n",
       "      <td>180758</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>177639</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>103406</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>235646</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45</td>\n",
       "      <td>Federal-gov</td>\n",
       "      <td>56904</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>5013</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt    education  education.num  \\\n",
       "0   29            Private  180758      Masters             14   \n",
       "1   34   Self-emp-not-inc  177639   Assoc-acdm             12   \n",
       "2   47          State-gov  103406      HS-grad              9   \n",
       "3   47   Self-emp-not-inc  235646      Masters             14   \n",
       "4   45        Federal-gov   56904    Bachelors             13   \n",
       "\n",
       "       marital.status        occupation    relationship    race    sex  \\\n",
       "0        Never-married   Prof-specialty   Not-in-family   White   Male   \n",
       "1        Never-married     Craft-repair   Not-in-family   White   Male   \n",
       "2   Married-civ-spouse     Tech-support         Husband   White   Male   \n",
       "3   Married-civ-spouse   Prof-specialty         Husband   White   Male   \n",
       "4   Married-civ-spouse     Adm-clerical         Husband   White   Male   \n",
       "\n",
       "   capital.gain  capital.loss  hours.per.week native.country   income  kfold  \n",
       "0             0             0              40   United-States   <=50K      0  \n",
       "1             0             0              40   United-States   <=50K      0  \n",
       "2             0             0              40   United-States   <=50K      0  \n",
       "3             0             0              40   United-States    >50K      0  \n",
       "4          5013             0              45   United-States   <=50K      0  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('adult_folds.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "kfold\n",
       "0    6513\n",
       "1    6512\n",
       "2    6512\n",
       "3    6512\n",
       "4    6512\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.kfold.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "      <th>income</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "      <td>Private</td>\n",
       "      <td>180758</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>177639</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>103406</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>235646</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45</td>\n",
       "      <td>Federal-gov</td>\n",
       "      <td>56904</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>5013</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6513</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>49893</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6514</th>\n",
       "      <td>32</td>\n",
       "      <td>Private</td>\n",
       "      <td>80058</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6515</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>197642</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6516</th>\n",
       "      <td>71</td>\n",
       "      <td>?</td>\n",
       "      <td>193863</td>\n",
       "      <td>7th-8th</td>\n",
       "      <td>4</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>?</td>\n",
       "      <td>Other-relative</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>Poland</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6517</th>\n",
       "      <td>20</td>\n",
       "      <td>Private</td>\n",
       "      <td>41721</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6513 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age          workclass  fnlwgt      education  education.num  \\\n",
       "0      29            Private  180758        Masters             14   \n",
       "1      34   Self-emp-not-inc  177639     Assoc-acdm             12   \n",
       "2      47          State-gov  103406        HS-grad              9   \n",
       "3      47   Self-emp-not-inc  235646        Masters             14   \n",
       "4      45        Federal-gov   56904      Bachelors             13   \n",
       "...   ...                ...     ...            ...            ...   \n",
       "6513   58            Private   49893   Some-college             10   \n",
       "6514   32            Private   80058        HS-grad              9   \n",
       "6515   58            Private  197642   Some-college             10   \n",
       "6516   71                  ?  193863        7th-8th              4   \n",
       "6517   20            Private   41721   Some-college             10   \n",
       "\n",
       "          marital.status        occupation     relationship    race      sex  \\\n",
       "0           Never-married   Prof-specialty    Not-in-family   White     Male   \n",
       "1           Never-married     Craft-repair    Not-in-family   White     Male   \n",
       "2      Married-civ-spouse     Tech-support          Husband   White     Male   \n",
       "3      Married-civ-spouse   Prof-specialty          Husband   White     Male   \n",
       "4      Married-civ-spouse     Adm-clerical          Husband   White     Male   \n",
       "...                   ...              ...              ...     ...      ...   \n",
       "6513   Married-civ-spouse            Sales          Husband   White     Male   \n",
       "6514   Married-civ-spouse     Adm-clerical          Husband   White     Male   \n",
       "6515        Never-married     Adm-clerical    Not-in-family   White   Female   \n",
       "6516              Widowed                ?   Other-relative   White   Female   \n",
       "6517        Never-married    Other-service        Own-child   White     Male   \n",
       "\n",
       "      capital.gain  capital.loss  hours.per.week native.country   income  \\\n",
       "0                0             0              40   United-States   <=50K   \n",
       "1                0             0              40   United-States   <=50K   \n",
       "2                0             0              40   United-States   <=50K   \n",
       "3                0             0              40   United-States    >50K   \n",
       "4             5013             0              45   United-States   <=50K   \n",
       "...            ...           ...             ...             ...     ...   \n",
       "6513             0             0              45   United-States   <=50K   \n",
       "6514             0             0              40   United-States   <=50K   \n",
       "6515             0             0              39   United-States   <=50K   \n",
       "6516             0             0              16          Poland   <=50K   \n",
       "6517             0             0              60   United-States   <=50K   \n",
       "\n",
       "      kfold  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "...     ...  \n",
       "6513      0  \n",
       "6514      0  \n",
       "6515      0  \n",
       "6516      0  \n",
       "6517      0  \n",
       "\n",
       "[6513 rows x 16 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.kfold==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\lia68085\\Git\\ml_learning\\textbook\\xgboost.ipynb Cell 28\u001b[0m line \u001b[0;36m8\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lia68085/Git/ml_learning/textbook/xgboost.ipynb#X40sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m: \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lia68085/Git/ml_learning/textbook/xgboost.ipynb#X40sZmlsZQ%3D%3D?line=81'>82</a>\u001b[0m     \u001b[39mfor\u001b[39;00m fold_ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m5\u001b[39m): \n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/lia68085/Git/ml_learning/textbook/xgboost.ipynb#X40sZmlsZQ%3D%3D?line=82'>83</a>\u001b[0m         run(fold_)\n",
      "\u001b[1;32mc:\\Users\\lia68085\\Git\\ml_learning\\textbook\\xgboost.ipynb Cell 28\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lia68085/Git/ml_learning/textbook/xgboost.ipynb#X40sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m model \u001b[39m=\u001b[39m linear_model\u001b[39m.\u001b[39mLogisticRegression() \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lia68085/Git/ml_learning/textbook/xgboost.ipynb#X40sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m \u001b[39m# fit model on training data (ohe) \u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/lia68085/Git/ml_learning/textbook/xgboost.ipynb#X40sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(x_train, df_train\u001b[39m.\u001b[39;49mincome\u001b[39m.\u001b[39;49mvalues) \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lia68085/Git/ml_learning/textbook/xgboost.ipynb#X40sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m \u001b[39m# predict on validation data \u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lia68085/Git/ml_learning/textbook/xgboost.ipynb#X40sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m \u001b[39m# we need the probability values as we are calculating AUC \u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lia68085/Git/ml_learning/textbook/xgboost.ipynb#X40sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m \u001b[39m# we will use the probability of 1s \u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lia68085/Git/ml_learning/textbook/xgboost.ipynb#X40sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m valid_preds \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict_proba(x_valid)[:, \u001b[39m1\u001b[39m] \n",
      "File \u001b[1;32mc:\\Users\\lia68085\\AppData\\Local\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\lia68085\\AppData\\Local\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1208\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1205\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1206\u001b[0m     _dtype \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39mfloat64, np\u001b[39m.\u001b[39mfloat32]\n\u001b[1;32m-> 1208\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m   1209\u001b[0m     X,\n\u001b[0;32m   1210\u001b[0m     y,\n\u001b[0;32m   1211\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1212\u001b[0m     dtype\u001b[39m=\u001b[39;49m_dtype,\n\u001b[0;32m   1213\u001b[0m     order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1214\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49msolver \u001b[39mnot\u001b[39;49;00m \u001b[39min\u001b[39;49;00m [\u001b[39m\"\u001b[39;49m\u001b[39mliblinear\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39msag\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39msaga\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m   1215\u001b[0m )\n\u001b[0;32m   1216\u001b[0m check_classification_targets(y)\n\u001b[0;32m   1217\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(y)\n",
      "File \u001b[1;32mc:\\Users\\lia68085\\AppData\\Local\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\base.py:622\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    620\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[0;32m    621\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 622\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    623\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\lia68085\\AppData\\Local\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\utils\\validation.py:1162\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1142\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1143\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1144\u001b[0m     )\n\u001b[0;32m   1146\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m   1147\u001b[0m     X,\n\u001b[0;32m   1148\u001b[0m     accept_sparse\u001b[39m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1159\u001b[0m     input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1160\u001b[0m )\n\u001b[1;32m-> 1162\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39;49mmulti_output, y_numeric\u001b[39m=\u001b[39;49my_numeric, estimator\u001b[39m=\u001b[39;49mestimator)\n\u001b[0;32m   1164\u001b[0m check_consistent_length(X, y)\n\u001b[0;32m   1166\u001b[0m \u001b[39mreturn\u001b[39;00m X, y\n",
      "File \u001b[1;32mc:\\Users\\lia68085\\AppData\\Local\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\utils\\validation.py:1184\u001b[0m, in \u001b[0;36m_check_y\u001b[1;34m(y, multi_output, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1182\u001b[0m     estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1183\u001b[0m     y \u001b[39m=\u001b[39m column_or_1d(y, warn\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m-> 1184\u001b[0m     _assert_all_finite(y, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39my\u001b[39;49m\u001b[39m\"\u001b[39;49m, estimator_name\u001b[39m=\u001b[39;49mestimator_name)\n\u001b[0;32m   1185\u001b[0m     _ensure_no_complex_data(y)\n\u001b[0;32m   1186\u001b[0m \u001b[39mif\u001b[39;00m y_numeric \u001b[39mand\u001b[39;00m y\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mO\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\lia68085\\AppData\\Local\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\utils\\validation.py:107\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[39mif\u001b[39;00m X\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mdtype(\u001b[39m\"\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_nan:\n\u001b[0;32m    106\u001b[0m     \u001b[39mif\u001b[39;00m _object_dtype_isnan(X)\u001b[39m.\u001b[39many():\n\u001b[1;32m--> 107\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mInput contains NaN\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    109\u001b[0m \u001b[39m# We need only consider float arrays, hence can early return for all else.\u001b[39;00m\n\u001b[0;32m    110\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m xp\u001b[39m.\u001b[39misdtype(X\u001b[39m.\u001b[39mdtype, (\u001b[39m\"\u001b[39m\u001b[39mreal floating\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcomplex floating\u001b[39m\u001b[39m\"\u001b[39m)):\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    " \n",
    "from sklearn import linear_model \n",
    "from sklearn import metrics \n",
    "from sklearn import preprocessing\n",
    "\n",
    "def run(fold): \n",
    "    # load the full training data with folds \n",
    "    df = pd.read_csv('adult_folds.csv')\n",
    " \n",
    "    # list of numerical columns \n",
    "    num_cols = [ \n",
    "        \"fnlwgt\", \n",
    "        \"age\", \n",
    "        \"capital.gain\", \n",
    "        \"capital.loss\", \n",
    "        \"hours.per.week\" ,\n",
    "        \"workclass\",\n",
    "        \"occupation\"\n",
    "\n",
    "    ] \n",
    " \n",
    "    # drop numerical columns \n",
    "    df = df.drop(num_cols, axis=1) \n",
    " \n",
    "    # map targets to 0s and 1s \n",
    "    target_mapping = { \n",
    "        \"<=50K\": 0, \n",
    "        \">50K\": 1 \n",
    "    } \n",
    "    df.loc[:, \"income\"] = df.income.map(target_mapping) \n",
    " \n",
    "    # all columns are features except income and kfold columns \n",
    "    features = [ \n",
    "        f for f in df.columns if f not in (\"kfold\", \"income\") \n",
    "    ] \n",
    " \n",
    "    # fill all NaN values with NONE \n",
    "    # note that I am converting all columns to \"strings\" \n",
    "    # it doesnt matter because all are categories \n",
    "    for col in features: \n",
    "        df.loc[:, col] = df[col].astype(str).fillna(\"NONE\") \n",
    "    # get training data using folds \n",
    "    df_train = df[df.kfold != fold].reset_index(drop=True) \n",
    " \n",
    "    # get validation data using folds \n",
    "    df_valid = df[df.kfold == fold].reset_index(drop=True) \n",
    " \n",
    "    # initialize OneHotEncoder from scikit-learn \n",
    "    ohe = preprocessing.OneHotEncoder() \n",
    " \n",
    "    # fit ohe on training + validation features \n",
    "    full_data = pd.concat( \n",
    "        [df_train[features], df_valid[features]], \n",
    "        axis=0)\n",
    "    ohe.fit(full_data[features]) \n",
    " \n",
    "    # transform training data \n",
    "    x_train = ohe.transform(df_train[features]) \n",
    " \n",
    "    # transform validation data \n",
    "    x_valid = ohe.transform(df_valid[features]) \n",
    " \n",
    "    # initialize Logistic Regression model \n",
    "    model = linear_model.LogisticRegression() \n",
    " \n",
    "    # fit model on training data (ohe) \n",
    "    model.fit(x_train, df_train.income.values) \n",
    " \n",
    "    # predict on validation data \n",
    "    # we need the probability values as we are calculating AUC \n",
    "    # we will use the probability of 1s \n",
    "    valid_preds = model.predict_proba(x_valid)[:, 1] \n",
    " \n",
    "    # get roc auc score \n",
    "    auc = metrics.roc_auc_score(df_valid.income.values, valid_preds) \n",
    " \n",
    "    # print auc \n",
    "    print(f\"Fold = {fold}, AUC = {auc}\")\n",
    "\n",
    "if __name__ == \"__main__\": \n",
    "    for fold_ in range(5): \n",
    "        run(fold_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_encoding.py \n",
    "import copy \n",
    "import pandas as pd \n",
    " \n",
    "from sklearn import metrics \n",
    "from sklearn import preprocessing \n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid classes inferred from unique values of `y`.  Expected: [    0     1     2 ... 26045 26046 26047], got [nan nan nan ... nan nan nan]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\lia68085\\Git\\ml_learning\\textbook\\xgboost.ipynb Cell 32\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/lia68085/Git/ml_learning/textbook/xgboost.ipynb#X42sZmlsZQ%3D%3D?line=123'>124</a>\u001b[0m df \u001b[39m=\u001b[39m mean_target_encoding(df) \n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/lia68085/Git/ml_learning/textbook/xgboost.ipynb#X42sZmlsZQ%3D%3D?line=124'>125</a>\u001b[0m \u001b[39mfor\u001b[39;00m fold_ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m5\u001b[39m): \n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/lia68085/Git/ml_learning/textbook/xgboost.ipynb#X42sZmlsZQ%3D%3D?line=125'>126</a>\u001b[0m     run(df, fold_)\n",
      "\u001b[1;32mc:\\Users\\lia68085\\Git\\ml_learning\\textbook\\xgboost.ipynb Cell 32\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lia68085/Git/ml_learning/textbook/xgboost.ipynb#X42sZmlsZQ%3D%3D?line=97'>98</a>\u001b[0m model \u001b[39m=\u001b[39m xgb\u001b[39m.\u001b[39mXGBClassifier( \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lia68085/Git/ml_learning/textbook/xgboost.ipynb#X42sZmlsZQ%3D%3D?line=98'>99</a>\u001b[0m     n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/lia68085/Git/ml_learning/textbook/xgboost.ipynb#X42sZmlsZQ%3D%3D?line=99'>100</a>\u001b[0m     max_depth\u001b[39m=\u001b[39m\u001b[39m7\u001b[39m \n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/lia68085/Git/ml_learning/textbook/xgboost.ipynb#X42sZmlsZQ%3D%3D?line=100'>101</a>\u001b[0m ) \n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/lia68085/Git/ml_learning/textbook/xgboost.ipynb#X42sZmlsZQ%3D%3D?line=102'>103</a>\u001b[0m \u001b[39m# fit model on training data (ohe) \u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/lia68085/Git/ml_learning/textbook/xgboost.ipynb#X42sZmlsZQ%3D%3D?line=103'>104</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(x_train, df_train\u001b[39m.\u001b[39;49mincome\u001b[39m.\u001b[39;49mvalues) \n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/lia68085/Git/ml_learning/textbook/xgboost.ipynb#X42sZmlsZQ%3D%3D?line=105'>106</a>\u001b[0m \u001b[39m# predict on validation data \u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/lia68085/Git/ml_learning/textbook/xgboost.ipynb#X42sZmlsZQ%3D%3D?line=106'>107</a>\u001b[0m \u001b[39m# we need the probability values as we are calculating AUC \u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/lia68085/Git/ml_learning/textbook/xgboost.ipynb#X42sZmlsZQ%3D%3D?line=107'>108</a>\u001b[0m \u001b[39m# we will use the probability of 1s \u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/lia68085/Git/ml_learning/textbook/xgboost.ipynb#X42sZmlsZQ%3D%3D?line=108'>109</a>\u001b[0m valid_preds \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict_proba(x_valid)[:, \u001b[39m1\u001b[39m] \n",
      "File \u001b[1;32mc:\\Users\\lia68085\\AppData\\Local\\anaconda3\\envs\\myenv\\lib\\site-packages\\xgboost\\core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    727\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[0;32m    728\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[1;32m--> 729\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\lia68085\\AppData\\Local\\anaconda3\\envs\\myenv\\lib\\site-packages\\xgboost\\sklearn.py:1467\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1462\u001b[0m     expected_classes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\n\u001b[0;32m   1463\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   1464\u001b[0m     classes\u001b[39m.\u001b[39mshape \u001b[39m!=\u001b[39m expected_classes\u001b[39m.\u001b[39mshape\n\u001b[0;32m   1465\u001b[0m     \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m (classes \u001b[39m==\u001b[39m expected_classes)\u001b[39m.\u001b[39mall()\n\u001b[0;32m   1466\u001b[0m ):\n\u001b[1;32m-> 1467\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1468\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid classes inferred from unique values of `y`.  \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1469\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpected: \u001b[39m\u001b[39m{\u001b[39;00mexpected_classes\u001b[39m}\u001b[39;00m\u001b[39m, got \u001b[39m\u001b[39m{\u001b[39;00mclasses\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1470\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_xgb_params()\n\u001b[0;32m   1474\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcallable\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective):\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid classes inferred from unique values of `y`.  Expected: [    0     1     2 ... 26045 26046 26047], got [nan nan nan ... nan nan nan]"
     ]
    }
   ],
   "source": [
    "def mean_target_encoding(data): \n",
    " \n",
    "    # make a copy of dataframe \n",
    "    df = copy.deepcopy(data) \n",
    " \n",
    "    # list of numerical columns \n",
    "    num_cols = [ \n",
    "        \"fnlwgt\", \n",
    "        \"age\", \n",
    "        \"capital.gain\", \n",
    "        \"capital.loss\", \n",
    "        \"hours.per.week\" \n",
    "    ] \n",
    " \n",
    "    # map targets to 0s and 1s \n",
    "    target_mapping = { \n",
    "        \"<=50K\": 0, \n",
    "        \">50K\": 1 \n",
    "    } \n",
    " \n",
    "    df.loc[:, \"income\"] = df.income.map(target_mapping) \n",
    "     \n",
    "    # all columns are features except income and kfold columns \n",
    "    features = [ \n",
    "        f for f in df.columns if f not in (\"kfold\", \"income\") \n",
    "        and f not in num_cols \n",
    "    ] \n",
    " \n",
    "    # all columns are features except kfold & income columns \n",
    "    features = [ \n",
    "        f for f in df.columns if f not in (\"kfold\", \"income\") \n",
    "    ] \n",
    " \n",
    "    # fill all NaN values with NONE\n",
    "    # note that I am converting all columns to \"strings\" \n",
    "    # it doesnt matter because all are categories \n",
    "    for col in features: \n",
    "        # do not encode the numerical columns \n",
    "        if col not in num_cols: \n",
    "            df.loc[:, col] = df[col].astype(str).fillna(\"NONE\") \n",
    "     \n",
    "    # now its time to label encode the features \n",
    "    for col in features: \n",
    "        if col not in num_cols:         \n",
    "            # initialize LabelEncoder for each feature column \n",
    "            lbl = preprocessing.LabelEncoder() \n",
    "             \n",
    "            # fit label encoder on all data \n",
    "            lbl.fit(df[col]) \n",
    " \n",
    "            # transform all the data \n",
    "            df.loc[:, col] = lbl.transform(df[col]) \n",
    " \n",
    "    # a list to store 5 validation dataframes \n",
    "    encoded_dfs = [] \n",
    " \n",
    "    # go over all folds \n",
    "    for fold in range(5): \n",
    "        # fetch training and validation data \n",
    "        df_train = df[df.kfold != fold].reset_index(drop=True) \n",
    "        df_valid = df[df.kfold == fold].reset_index(drop=True) \n",
    "        # for all feature columns, i.e. categorical columns \n",
    "        for column in features: \n",
    "            # create dict of category:mean target \n",
    "            mapping_dict = dict( \n",
    "                df_train.groupby(column)[\"income\"].mean() \n",
    "            ) \n",
    "            # column_enc is the new column we have with mean encoding \n",
    "            df_valid.loc[ \n",
    "                :, column + \"_enc\" \n",
    "            ] = df_valid[column].map(mapping_dict) \n",
    "        # append to our list of encoded validation dataframes \n",
    "        encoded_dfs.append(df_valid) \n",
    "    # create full data frame again and return \n",
    "    encoded_df = pd.concat(encoded_dfs, axis=0) \n",
    "    return encoded_df\n",
    "\n",
    "def run(df, fold): \n",
    "    # note that folds are same as before \n",
    "    # get training data using folds \n",
    "    df_train = df[df.kfold != fold].reset_index(drop=True) \n",
    " \n",
    "    # get validation data using folds \n",
    "    df_valid = df[df.kfold == fold].reset_index(drop=True) \n",
    " \n",
    "    # all columns are features except income and kfold columns \n",
    "    features = [ \n",
    "        f for f in df.columns if f not in (\"kfold\", \"income\") \n",
    "    ] \n",
    " \n",
    "    # scale training data \n",
    "    x_train = df_train[features].values \n",
    " \n",
    "    # scale validation data \n",
    "    x_valid = df_valid[features].values \n",
    " \n",
    "    # initialize xgboost model \n",
    "    model = xgb.XGBClassifier( \n",
    "        n_jobs=-1, \n",
    "        max_depth=7 \n",
    "    ) \n",
    " \n",
    "    # fit model on training data (ohe) \n",
    "    model.fit(x_train, df_train.income.values) \n",
    " \n",
    "    # predict on validation data \n",
    "    # we need the probability values as we are calculating AUC \n",
    "    # we will use the probability of 1s \n",
    "    valid_preds = model.predict_proba(x_valid)[:, 1] \n",
    " \n",
    "    # get roc auc score \n",
    "    auc = metrics.roc_auc_score(df_valid.income.values, valid_preds) \n",
    " \n",
    "    # print auc \n",
    "    print(f\"Fold = {fold}, AUC = {auc}\") \n",
    " \n",
    " \n",
    "if __name__ == \"__main__\": \n",
    "    # read data \n",
    "    df = pd.read_csv(\"adult_folds.csv\") \n",
    "     \n",
    "    # create mean target encoded categories and \n",
    "    # munge data \n",
    "    df = mean_target_encoding(df) \n",
    "    for fold_ in range(5): \n",
    "        run(df, fold_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
